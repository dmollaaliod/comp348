{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simple Statistics and NLTK\n",
    "\n",
    "The following exercises use a portion of the Gutenberg corpus that is stored in the corpus dataset of NLTK. [The Project Gutenberg](http://www.gutenberg.org/) is a large collection of electronic books that are out of copyright. These books are free to download for reading, or for our case, for doing a little of corpus analysis.\n",
    "\n",
    "To obtain the list of files of NLTK's Gutenberg corpus, type the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain all words in the entire Gutenberg corpus of NLTK, type the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gutenbergwords = nltk.corpus.gutenberg.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can find the total number of words, and the first 10 words (do not attempt to display all the words or your computer will freeze!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621613"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gutenbergwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenbergwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find the words of just a selection of documents, as shown below. For more details of what information you can extract from this corpus, read the \"Gutenberg corpus\" section of the [NLTK book chapter 2](http://www.nltk.org/book_1ed/ch02.html), section 2.1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "*Find the most frequent word with length of at least 7 characters in the complete Gutenberg corpus.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Woodhouse',\n",
       " 'handsome',\n",
       " 'comfortable',\n",
       " 'disposition',\n",
       " 'blessings',\n",
       " 'existence',\n",
       " 'distress',\n",
       " 'youngest',\n",
       " 'daughters',\n",
       " 'affectionate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "*Find the words that are longer than 7 characters and occur more than 7 times in the complete Gutenberg corpus.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('withdrawn', 22),\n",
       " ('esteemed', 23),\n",
       " ('desperately', 16),\n",
       " ('including', 23),\n",
       " ('thousand', 752)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3\n",
    "*Find the average number of words across the documents of the NLTK Gutenberg corpus.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145645.16666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4\n",
    "*Find the Gutenberg document with the longest average word length.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with largest average word length is milton-paradise.txt with word length 4.835734572682675\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.5\n",
    "*Find the 10 most frequent bigrams in the entire Gutenberg corpus.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', 'and'), 41294),\n",
       " (('of', 'the'), 18912),\n",
       " (('in', 'the'), 9793),\n",
       " ((\"'\", 's'), 9781),\n",
       " ((';', 'and'), 7559),\n",
       " (('and', 'the'), 6432),\n",
       " (('the', 'LORD'), 5964),\n",
       " ((',', 'the'), 5957),\n",
       " ((',', 'I'), 5677),\n",
       " ((',', 'that'), 5352)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.6\n",
    "*Find the most frequent bigram that begins with \"Moby\" in Herman Melville's \"Moby Dick\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Moby', 'Dick'), 83), (('Moby', '-'), 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regular Expressions\n",
    "The aim of this section is to develop a regular expression that detects all the numerical expressions in the Brown corpus. The Brown corpus is described in the [NLTK book chapter 2](http://www.nltk.org/book_1ed/ch02.html), section 2.1.\n",
    "\n",
    "The Brown corpus is a corpus annotated with the parts of speech. In the following exercises, you will concentrate on the words tagged with labels that begin with the `CD` tag. This tag stands for \"cardinal numeral\" and indicates that the token is a number. For the full list of tags in the Brown corpus you can see the [Wikipedia entry](https://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used).\n",
    "\n",
    "The following Python code shows the first 5 words of the \"news\" category of the Brown corpus. You'll see that it is a list of pairs, where each pair is a word and a tag. The tag has two components separated with `-`. We will focus on the labels that begin with `'CD'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "tagged = nltk.corpus.brown.tagged_words(categories='news')\n",
    "tagged[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "*Write code that finds all the numbers (items tagged with `'CD'`) and stores them in a variable. How many numbers are there? How many different numbers are there?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code stores the list of unannotated tokens in the variable `tokens`. Note that we could have used `nltk.corpus.brown.words()` but the code below makes sure that the list mirrors the previously list `tagged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2\n",
    "*Find all the items in `tokens` that match the following regular expression: `^[0-9]+$`. Write the result as a list of pairs `(word,annotation)` so that, if the word is a number, the annotation is `'CD'`, and if it is not a number, the annotation is `''`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def annotateNum(listtokens):\n",
    "    \"\"\"Annotate the list of tokens to identify the numbers.\n",
    "    Example of run:\n",
    "    >>> annotateNum(['the','number','5'])\n",
    "    [('the', ''), ('number', ''), ('5', 'CD')]\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', ''), ('number', ''), ('5', 'CD')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotateNum(['the','number','5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code computes the recall and precision of the annotations.\n",
    "\n",
    "1. The *recall* is the ratio of numbers that are tagged correctly.\n",
    "2. The *precision* is the ratio of tagged tokens that are numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(result,tagged):\n",
    "    assert len(result) == len(tagged) # This is a check that the length of the result and tagged are equal\n",
    "    correct = [result[i][0] for i in range(len(result)) if result[i][1][:2] == 'CD' and tagged[i][1][:2] == 'CD']\n",
    "    numbers_result = [result[i][0] for i in range(len(result)) if result[i][1][:2] == 'CD']\n",
    "    numbers_tagged = [tagged[i][0] for i in range(len(tagged)) if tagged[i][1][:2] == 'CD']\n",
    "    print(\"Recall:\",len(correct)/len(numbers_tagged))\n",
    "    print(\"Precision:\",len(correct)/len(numbers_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5304428044280443\n",
      "Precision: 0.9982638888888888\n"
     ]
    }
   ],
   "source": [
    "evaluate(annotateNum(tokens),tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code returns the mistakes that you produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def false_positives(result,tagged):\n",
    "    \"Return the non-numbers that were tagged as numbers\"\n",
    "    return [tagged[i] for i in range(len(result)) if result[i][1]== 'CD' and tagged[i][1][:2] != 'CD']\n",
    "def false_negatives(result,tagged):\n",
    "    \"Return the numbers that were not tagged as numbers\"\n",
    "    return [result[i] for i in range(len(result)) if result[i][1]!= 'CD' and tagged[i][1][:2] == 'CD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', 'OD'), ('3', 'OD-TL')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives(annotateNum(tokens),tagged)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('two', ''),\n",
       " ('one', ''),\n",
       " ('two', ''),\n",
       " ('Four', ''),\n",
       " ('one', ''),\n",
       " ('one', ''),\n",
       " ('one', ''),\n",
       " ('two', ''),\n",
       " ('Five', ''),\n",
       " ('three', '')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives(annotateNum(tokens),tagged)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3 \n",
    "*Concentrate on your worst figure, either recall and precision, and try to improve it:*\n",
    "\n",
    "1. *If recall is low, list all the numbers that your system failed to detect (the false negatives). With those numbers in mind, update your regular expression.*\n",
    "2. *If precision is low, list all the tokens that your system erroneously classified as numbers (the false positives). The update your regular expression to cover those words.*\n",
    "\n",
    "*Test your new regular expression on the full Brown corpus, compute recall and precision, and see what you can improve. Do this several times and try to get better results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
